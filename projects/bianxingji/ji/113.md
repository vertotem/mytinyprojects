# 113-正确≠应该

> 所有论题都可以归结为三个基本模态：是不是，好不好，应不应。三者互不兼容。

两年前，我曾经问一个人工智能方面的专家：AI代写论文，有多大的可行性？​

毫无疑问，这是面对未来科技，一个高校教师最底层的恐惧。我已经做好心理准备，接受最糟糕的答案。然而对方的回答，比我想象的更糟糕。

不是惊吓，而是羞辱。

你肯定知道，最严重的羞辱，不是看不起，而是看不见。不是“你太差了”，而是“你差不差都没差”。当时这位老兄就是这么说的：

“技术上，这不难；但是经济上，没这个必要。”

帮你们写论文？没问题啊！可是，你们本来劳动力也不值钱，何必让宝贵AI干这么琐碎的事情呢？

当然，后一句是我自己找补出来的，对方纯粹就是在做技术和商业的分析，毫无褒贬之意。但是有一个信息是明确的：“论述”特定主题（这是论文的核心），根本不是什么高难度的事情，甚至可以说是“智能”的基础，根本没必要专门进行开发。

所以我当时的想法是，等AI技术发展到一定程度，“写论文”很可能就会像是“美颜”一样，变成一个在更高大上的核心科技基础上，顺便开发出来的应用。等着呗。

直到两周以前的一则消息。

IBM的人工辩手Project Debater，跟人类真刀真枪地干了一场。

我知道，在2018年6月就有类似的新闻，当时AI的对手是两个以色列的大学生。但那时候的官方说法是，这场比赛证明人工智能是“强大的”（formidable）辩论对手，而IBM方面并没有试图裁决胜负。明眼人都能看出来，这是客套，就像是老师再怎么跟学生说“后生可畏”，心底里还是觉得不在一个层次上。有条尖酸的评论说（Chirs Reed，Dundee大学计算机科学教授）：“AI是不错，但是跟人类在辩论上分庭抗礼还早着呢，就好比古罗马人也会倒腾蒸汽，但是跟工业革命时代的蒸汽机，能是一回事吗？”（we are most certainly not on the verge of seeing AI systems out-debating their human counterparts. Today’s AI technology is as far from these scenarios as the Romans’ experiments with steam power were from the industrial revolution.）

但是这次不一样，这次是现场800多观众以“跳票”（辩论前统计现场观众对辩题的原有立场，辩论之后看多少人改变了原立场）方式评判胜负，是玩真的。

还好人类辩手赢了，对于“不应该补贴学前教育”这个立场，Harish Natarajan把支持率从13％拉升到30％，我看了视频，觉得他赢得毫无争议，因为AI纵然语言流畅论证详实甚至还有辩证头脑和幽默细胞，但它无法理解一个人类世界的常识：正确≠应该。

严格来说，在最聪明的人那里，正确，应该就等于是“应该”。比如《星际迷航》里的史波克，牺牲自己拯救队友，别人哭成泪人跟他绝别，他却疑惑地问：牺牲我一个救你们一大堆，这难道不是正确的选择吗？有什么好哭的呢？

看，这就是一个典型的AI思维。你无法说他不对，你只能说：我们人类不是这个样子的。

对于人类而言，所有值得争论的话题，都可以归结为三个母题：是不是，好不好，应不应。比如说，苹果是不是有营养？这是第一层。苹果好不好吃？这是第二层。你现在要不要吃苹果？这是第三层。从死硬理性的角度说，一（正确）可以导致出三（应该）；从感性的角度说，二（喜欢）可以推导出三（应该）。问题是，在政策辩论里，一和二，都推导不出三；一加二，也推导不出三（因为可能还可以吃别的）。人类之所以是一种复杂的动物，社会决策之所以是一个复杂的过程，奥妙就在这里。

什么意思？就拿“是否应该补贴学前教育”这个辩题来说，IBM的Project Debater立论简单明了：道德上，我们有帮助弱势群体的义务；利益上，学前教育跟孩子未来的发展有极强的正相关性。又好又对，凭什么不应该呢？

人类的辩手马上教它做人：在真实的世界里，选择，不是这样做的（他反复强调了“真实世界”和“做选择”这两个概念）——同样的资源，为什么投入到学前教育而不是别的项目？你让其他需要帮助的穷人怎么想？补贴学前教育，（原本无论如何也会送孩子去幼儿园的）中产阶级同样也会受益，你怎么保证这钱是专门花在穷人身上的？甚至场外还有观众评论说，这里是美国（辩论地点在旧金山），美国人一听到“对穷人的义务”这种话就心烦，就不能换个说法吗？

你看，这才是真实的人类，是AI（至少目前）无法理解的人类。

对于这一类的反驳，AI的回应非常AI：我们探讨的是一个limited&tragetd的问题，而且联邦预算有好大一坨，花在学前教育上的这点没啥了不起的，所以（人类辩手的主要反驳理由）扯别的地方也要花钱是“不相关的”（irrelevant）。然后，AI就开始进一步强化自己的正面论述，去讲学前教育的各种好处。

作为一个人，你觉得有什么问题不？

没有什么拿得出手的理由说它有问题，但就是觉得有问题，对不对？

还是那句话：真实世界里的决策，不是这样做的。也许这个真实世界并不完美，也许归根到底，我们应该像AI那样做决策，但是again，真实的决策过程，不是这个样子的。花钱的地方很多，每个都有无数的正当理由，谁耐烦听？你要证明的，不是你值得，而是你比别人更值得。说白了，你得把别人拉下水（比如一个最low的论述是：每年浪费都要浪费这么多，省下来一点不就够了？虽然这句话本身没什么道理，但是更符合人性的直觉），才能证明自己的必要性。

我知道以上这段话会挨骂，因为听起来又肮脏又非理性。然而问题是，人类本来就这么脏，就这么非理性。不信你回想一下，广告商在向你兜售商品的时候，是在向你描述参数还是愿景？是诉诸你的理性还是渴望？你再想想，你觉得正确的事，跟你觉得喜欢的事，跟你真正来讲经常在做的事，真的都是一回事吗？

我们每个人，都是认同好好学习最重要，觉得自己喜欢美食和摄影，然后把大多数的时间，都花在吃垃圾食品和刷手机上。在英明神武的AI面前，我们都是渣。然而反过来说，不管AI把自己包装得多像一个辩手，在真正洞察人心的辩手面前，它也是渣。

好辩手，就是既理解AI强在哪，也理解它渣在哪的人。

最后，额外送个脑洞——如果AI真的成为了好辩手，又待怎讲？嘿嘿，到那个时候，AI就会跟人类一样渣，怕它做甚？